{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank marketing data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([39922,  5289])) 45211\n",
      "(10578, 81) 10578\n",
      "(array([0, 1]), array([5289, 5289])) 10578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/bank/bank-full.csv\", sep=';').dropna()\n",
    "data = pd.get_dummies(data, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day', 'month', 'poutcome'])\n",
    "data['y'] = data['y'].astype('category')\n",
    "data['y'] = data['y'].cat.codes\n",
    "y = data.pop('y').values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "print(np.unique(y, return_counts=True), len(y))\n",
    "\n",
    "# Random downsample majority class\n",
    "sample = random.sample(np.arange(len(y))[y == 0].tolist(), 5289)\n",
    "X = np.concatenate((X[sample,], X[y==1,]))\n",
    "y = np.concatenate((y[sample], y[y==1]))\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(X.shape, len(y))\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X)\n",
    "data['y'] = y\n",
    "data.to_csv(\"../../Datasets/bank/bank-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banknote data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([762, 610])) 1372 (1372, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/banknote_authentication.txt\", sep=',', header=None).dropna()\n",
    "y = data.pop(4).values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y), X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ids_train = []\n",
    "ids_test = []\n",
    "\n",
    "for i in range(20):\n",
    "    id_train, id_test = train_test_split(np.arange(len(y)), test_size=.3)\n",
    "    ids_train.append(id_train)\n",
    "    ids_test.append(id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([7, 3]))\n",
      "(array([0, 1]), array([4, 6]))\n",
      "(array([0, 1]), array([5, 5]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([4, 6]))\n",
      "(array([0, 1]), array([5, 5]))\n",
      "(array([0, 1]), array([6, 4]))\n",
      "(array([0, 1]), array([5, 5]))\n",
      "(array([0, 1]), array([7, 3]))\n",
      "(array([0, 1]), array([4, 6]))\n",
      "(array([0, 1]), array([3, 7]))\n",
      "(array([0, 1]), array([6, 4]))\n",
      "(array([0, 1]), array([6, 4]))\n",
      "(array([0, 1]), array([2, 8]))\n",
      "(array([0, 1]), array([5, 5]))\n",
      "(array([0, 1]), array([4, 6]))\n",
      "(array([0, 1]), array([7, 3]))\n",
      "(array([0, 1]), array([5, 5]))\n",
      "(array([0, 1]), array([6, 4]))\n",
      "(array([0, 1]), array([6, 4]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(np.unique(y[ids_train[i][:10]], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('splits/trsplitbanknote', ids_train)\n",
    "np.savez_compressed('splits/tstsplitbanknote', ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart disease data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([160,  54,  35,  35,  13])) 297\n",
      "(array([0, 1]), array([160, 137])) 297\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/processed.cleveland.data\", sep=',', header=None).dropna()\n",
    "y = data.pop(13).values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))\n",
    "y[y > 0] = 1\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather in Australia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([43993, 12427])) 56420\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/weatherAUS.csv\").dropna()\n",
    "data = data.drop(['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1)\n",
    "data['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "data['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "y = data.pop('RainTomorrow').values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ids_train = []\n",
    "ids_test = []\n",
    "\n",
    "for i in range(20):\n",
    "    id_train, id_test = train_test_split(np.arange(len(y)), test_size=.3)\n",
    "    ids_train.append(id_train)\n",
    "    ids_test.append(id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([6, 4]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([7, 3]))\n",
      "(array([0, 1]), array([5, 5]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([6, 4]))\n",
      "(array([0, 1]), array([8, 2]))\n",
      "(array([0, 1]), array([9, 1]))\n",
      "(array([0, 1]), array([9, 1]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(np.unique(y[ids_train[i][:10]], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('splits/trsplitweather', ids_train)\n",
    "np.savez_compressed('splits/tstsplitbanknote', ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([444, 239])) 683\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/breast-cancer-wisconsin.data\", sep=',', header=None).dropna()\n",
    "data = data.drop(0, axis=1)\n",
    "data[10].replace({2: 0, 4: 1}, inplace = True)\n",
    "y = data.pop(10).values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([424, 290])) 714\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/titanic.csv\")\n",
    "data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "data['Sex'].replace({'female': 0, 'male': 1}, inplace = True)\n",
    "data = data.dropna()\n",
    "y = data.pop('Survived').values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([500, 268])) 768\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/diabetes.csv\").dropna()\n",
    "y = data.pop('Outcome').values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 97, 111])) 208\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/sonar.all-data\", sep=',', header=None).dropna()\n",
    "data[60].replace({'R': 0, 'M': 1}, inplace = True)\n",
    "y = data.pop(60).values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([699, 356])) 1055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../Datasets/biodeg.csv\", sep=';', header=None).dropna()\n",
    "data[41].replace({'NRB': 0, 'RB': 1}, inplace = True)\n",
    "y = data.pop(41).values.astype(int)\n",
    "X = data.values.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "print(np.unique(y, return_counts=True), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save 20 random split indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save split :  0\n",
      "(array([0, 1]), array([34, 16])) 50\n",
      "save split :  1\n",
      "(array([0, 1]), array([34, 16])) 50\n",
      "save split :  2\n",
      "(array([0, 1]), array([33, 17])) 50\n",
      "save split :  3\n",
      "(array([0, 1]), array([31, 19])) 50\n",
      "save split :  4\n",
      "(array([0, 1]), array([37, 13])) 50\n",
      "save split :  5\n",
      "(array([0, 1]), array([36, 14])) 50\n",
      "save split :  6\n",
      "(array([0, 1]), array([35, 15])) 50\n",
      "save split :  7\n",
      "(array([0, 1]), array([34, 16])) 50\n",
      "save split :  8\n",
      "(array([0, 1]), array([37, 13])) 50\n",
      "save split :  9\n",
      "(array([0, 1]), array([36, 14])) 50\n",
      "save split :  10\n",
      "(array([0, 1]), array([33, 17])) 50\n",
      "save split :  11\n",
      "(array([0, 1]), array([35, 15])) 50\n",
      "save split :  12\n",
      "(array([0, 1]), array([35, 15])) 50\n",
      "save split :  13\n",
      "(array([0, 1]), array([33, 17])) 50\n",
      "save split :  14\n",
      "(array([0, 1]), array([34, 16])) 50\n",
      "save split :  15\n",
      "(array([0, 1]), array([36, 14])) 50\n",
      "save split :  16\n",
      "(array([0, 1]), array([30, 20])) 50\n",
      "save split :  17\n",
      "(array([0, 1]), array([35, 15])) 50\n",
      "save split :  18\n",
      "(array([0, 1]), array([30, 20])) 50\n",
      "save split :  19\n",
      "(array([0, 1]), array([34, 16])) 50\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    print('save split : ', i)\n",
    "    id_split, id_test = train_test_split(np.arange(len(y)), test_size=.33)\n",
    "    id_l, id_u = train_test_split(id_split, train_size=50, random_state=2020)\n",
    "    print(np.unique(y[id_l], return_counts=True), len(y[id_l]))\n",
    "    Datasets.save_obj(id_test, 'qsar_test_'+str(i))\n",
    "    Datasets.save_obj(id_l, 'qsar_l_'+str(i))\n",
    "    Datasets.save_obj(id_u, 'qsar_u_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 706)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_test), len(id_l) + len(id_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65243553008596 0.01885682909314944\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from self_learning import msla\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "err_SLA = []\n",
    "\n",
    "for i in range(20):\n",
    "    id_l = Datasets.load_obj('qsar_l_'+str(i))\n",
    "    id_u = Datasets.load_obj('qsar_u_'+str(i))\n",
    "    id_test = Datasets.load_obj('qsar_test_'+str(i))\n",
    "    H0, Xl, yl, Xu, yu, thetas, _ = msla(X[id_l,], y[id_l], X[id_u,], random_state=2020)\n",
    "    err_SLA.append(accuracy_score(y[id_test], H0.predict(X[id_test,])))\n",
    "print(np.mean(err_SLA), np.std(err_SLA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 labeled data :  0.6525787965616047 0.018764627110973188\n",
      "all labeled data :  0.8001432664756447 0.028218404555866106\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scr_all = []\n",
    "scr_50 = []\n",
    "\n",
    "for i in range(20):\n",
    "    id_l = Datasets.load_obj('qsar_l_'+str(i))\n",
    "    id_u = Datasets.load_obj('qsar_u_'+str(i))\n",
    "    id_all = np.concatenate((id_l, id_u))\n",
    "    id_test = Datasets.load_obj('qsar_test_'+str(i))\n",
    "    svm_all = LinearSVC(random_state=2020)\n",
    "    svm_all.fit(X[id_all,], y[id_all])\n",
    "    scr_all.append(svm_all.score(X[id_test,], y[id_test]))\n",
    "    svm_50 = LinearSVC(random_state=2020)\n",
    "    svm_50.fit(X[id_l,], y[id_l])\n",
    "    scr_50.append(svm_50.score(X[id_test,], y[id_test]))\n",
    "    \n",
    "print('50 labeled data : ', np.mean(scr_50), np.std(scr_50))\n",
    "print('all labeled data : ', np.mean(scr_all), np.std(scr_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 labeled data :  0.7373737373737373 0.0\n",
      "all labeled data :  0.8181818181818182 0.0\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from linear_models import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scr_all = []\n",
    "scr_50 = []\n",
    "\n",
    "for i in range(1):\n",
    "    id_l = Datasets.load_obj('heart_l_'+str(i))\n",
    "    id_u = Datasets.load_obj('heart_u_'+str(i))\n",
    "    id_all = np.concatenate((id_l, id_u))\n",
    "    id_test = Datasets.load_obj('heart_test_'+str(i))\n",
    "    LTF_all = Halfspace()\n",
    "    LTF_all.fit(X[id_all,], y[id_all])\n",
    "    scr_all.append(LTF_all.score(X[id_test,], y[id_test]))\n",
    "    LTF_50 = Halfspace()\n",
    "    LTF_50.fit(X[id_l,], y[id_l])\n",
    "    scr_50.append(LTF_50.score(X[id_test,], y[id_test]))\n",
    "    \n",
    "print('50 labeled data : ', np.mean(scr_50), np.std(scr_50))\n",
    "print('all labeled data : ', np.mean(scr_all), np.std(scr_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 labeled data :  0.7575757575757576 0.0\n",
      "all labeled data :  0.8383838383838383 0.0\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from linear_models import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scr_all = []\n",
    "scr_50 = []\n",
    "\n",
    "for i in range(1):\n",
    "    id_l = Datasets.load_obj('heart_l_'+str(i))\n",
    "    id_u = Datasets.load_obj('heart_u_'+str(i))\n",
    "    id_all = np.concatenate((id_l, id_u))\n",
    "    id_test = Datasets.load_obj('heart_test_'+str(i))\n",
    "    LTF_all = Halfspace()\n",
    "    LTF_all.fit(X[id_all,], y[id_all])\n",
    "    scr_all.append(LTF_all.score(X[id_test,], y[id_test]))\n",
    "    LTF_50 = Halfspace()\n",
    "    LTF_50.fit(X[id_l,], y[id_l])\n",
    "    scr_50.append(LTF_50.score(X[id_test,], y[id_test]))\n",
    "    \n",
    "print('50 labeled data : ', np.mean(scr_50), np.std(scr_50))\n",
    "print('all labeled data : ', np.mean(scr_all), np.std(scr_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
