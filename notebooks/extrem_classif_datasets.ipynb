{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediamill dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43907, 120, 101)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from xclib.data import data_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features, tabels, num_samples, num_features, num_labels = data_utils.read_data('../../Datasets/Mediamill/Mediamill_data.txt')\n",
    "trSplit = pd.read_csv(\"../../Datasets/Mediamill/mediamill_trSplit.txt\", header=None, sep=' ').dropna()\n",
    "tstSplit = pd.read_csv(\"../../Datasets/Mediamill/mediamill_tstSplit.txt\", header=None, sep=' ').dropna()\n",
    "X = features.todense()\n",
    "X = X.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "labels = tabels.todense()\n",
    "np.savez_compressed('../mediamill', x=X, lab=labels)\n",
    "num_samples, num_features, num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([15969, 27938]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msq = np.argsort(np.ravel(np.sum(labels, axis=0, dtype=int)))\n",
    "np.unique(np.ravel(labels[:,msq[-2]]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(labels[:,msq[-2]]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12914"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tstSplit[0]), len(tSplit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6364797893758711 0.0015737673505691015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    clf = LinearSVC(random_state=2020)\n",
    "    clf.fit(X[trSplit[i].values[:50]-1,], y[trSplit[i].values[:50]-1])\n",
    "    err.append(clf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6934412265758092 0.0016118645760910245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    clf = LinearSVC(random_state=2020)\n",
    "    clf.fit(X[trSplit[i].values-1,], y[trSplit[i].values-1])\n",
    "    err.append(clf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6646662536781787 0.031555376716985\n"
     ]
    }
   ],
   "source": [
    "from linear_models import *\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    ltf = Halfspace()\n",
    "    ltf.fit(X[trSplit[i].values[:50]-1,], y[trSplit[i].values[:50]-1])\n",
    "    err.append(ltf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6364797893758711 0.0015737673505691015\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from self_learning import msla\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "err_SLA = []\n",
    "\n",
    "for i in range(10):\n",
    "    id_l = trSplit[i].values[:50]-1\n",
    "    id_u = trSplit[i].values[:50]-1\n",
    "    id_test = tstSplit[i].values-1\n",
    "    H0, Xl, yl, Xu, yu, thetas, _ = msla(X[id_l,], y[id_l], X[id_u,], random_state=2020)\n",
    "    err_SLA.append(accuracy_score(y[id_test], H0.predict(X[id_test,])))\n",
    "print(np.mean(err_SLA), np.std(err_SLA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibtex dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7395, 1836, 159)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from xclib.data import data_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features, tabels, num_samples, num_features, num_labels = data_utils.read_data('../../Datasets/Bibtex/Bibtex_data.txt')\n",
    "trSplit = pd.read_csv(\"../../Datasets/Bibtex/bibtex_trSplit.txt\", header=None, sep=' ').dropna()\n",
    "tstSplit = pd.read_csv(\"../../Datasets/Bibtex/bibtex_tstSplit.txt\", header=None, sep=' ').dropna()\n",
    "X = features.todense()\n",
    "X = X.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "labels = tabels.todense()\n",
    "np.savez_compressed('../bibtex', x=X, lab=labels)\n",
    "num_samples, num_features, num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([6353, 1042]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msq = np.argsort(np.ravel(np.sum(labels, axis=0, dtype=int)))\n",
    "np.unique(np.ravel(labels[:,msq[-1]]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2515, 4880)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ravel(labels[:,msq[-1]]).astype(int)\n",
    "len(tstSplit[0]), len(trSplit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8589264413518887 0.004564085837703927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    clf = LinearSVC(random_state=2020)\n",
    "    clf.fit(X[trSplit[i].values[:50]-1,], y[trSplit[i].values[:50]-1])\n",
    "    err.append(clf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999204771371769 0.00015904572564613416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    clf = LinearSVC(random_state=2020)\n",
    "    clf.fit(X[trSplit[i].values-1,], y[trSplit[i].values-1])\n",
    "    err.append(clf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8610735586481113 0.007838550476565639\n"
     ]
    }
   ],
   "source": [
    "from linear_models import *\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    ltf = Halfspace()\n",
    "    ltf.fit(X[trSplit[i].values[:50]-1,], y[trSplit[i].values[:50]-1])\n",
    "    err.append(ltf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9650099403578528 0.002943420361562099\n"
     ]
    }
   ],
   "source": [
    "from linear_models import *\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    ltf = Halfspace()\n",
    "    ltf.fit(X[trSplit[i].values-1,], y[trSplit[i].values-1])\n",
    "    err.append(ltf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8588866799204771 0.004559407122135116\n"
     ]
    }
   ],
   "source": [
    "from data_gen import *\n",
    "from self_learning import msla\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "err_SLA = []\n",
    "\n",
    "for i in range(10):\n",
    "    id_l = trSplit[i].values[:50]-1\n",
    "    id_u = trSplit[i].values[:50]-1\n",
    "    id_test = tstSplit[i].values-1\n",
    "    H0, Xl, yl, Xu, yu, thetas, _ = msla(X[id_l,], y[id_l], X[id_u,], random_state=2020)\n",
    "    err_SLA.append(accuracy_score(y[id_test], H0.predict(X[id_test,])))\n",
    "print(np.mean(err_SLA), np.std(err_SLA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delicious dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16105, 500, 983)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from xclib.data import data_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features, tabels, num_samples, num_features, num_labels = data_utils.read_data('../../Datasets/Delicious/Delicious_data.txt')\n",
    "trSplit = pd.read_csv(\"../../Datasets/Delicious/delicious_trSplit.txt\", header=None, sep=' ').dropna()\n",
    "tstSplit = pd.read_csv(\"../../Datasets/Delicious/delicious_tstSplit.txt\", header=None, sep=' ').dropna()\n",
    "X = features.todense()\n",
    "X = X.astype('float32')\n",
    "X = normalize(X, norm='l2', axis=0)\n",
    "labels = tabels.todense()\n",
    "np.savez_compressed('../delicious', x=X, lab=labels)\n",
    "num_samples, num_features, num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([9610, 6495]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msq = np.argsort(np.ravel(np.sum(labels, axis=0, dtype=int)))\n",
    "np.unique(np.ravel(labels[:,msq[-1]]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3185, 12920)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ravel(labels[:,msq[-1]]).astype(int)\n",
    "len(tstSplit[0]), len(trSplit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6004395604395604 0.00620394180560496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    clf = LinearSVC(random_state=2020)\n",
    "    clf.fit(X[trSplit[i].values[:50]-1,], y[trSplit[i].values[:50]-1])\n",
    "    err.append(clf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6505494505494507 0.005035308055693424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "err = []\n",
    "for i in range(10):\n",
    "    clf = LinearSVC(random_state=2020)\n",
    "    clf.fit(X[trSplit[i].values-1,], y[trSplit[i].values-1])\n",
    "    err.append(clf.score(X[tstSplit[i].values-1,], y[tstSplit[i].values-1]))\n",
    "print(np.mean(err), np.std(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
